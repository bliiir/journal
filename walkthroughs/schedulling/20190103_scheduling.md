*Journal*
Rasmus Groth
*Created: 20190103, Utterslev, Copenhagen, Denmark*
*Edited: 20190813, Utterslev, Copenhagen, Denmark*

# Automated Realtime Algorithmic Cryptocurrency Trading
### Setting up concurrent and parallel excution of multiple python scripts
We are setting up a trading platform and we need a simple, robust way of ensuring that we are executing trades at appropriate times and on time.

---

## Initial considerations
The most critical thing is to be able to post orders concurrently on the exchange.


### Criteria
- Less = more
- Simple = better
- Done > perfect

### Setup
- Postgres database is on an AWS RDS server and is automatically recovered by Amazon if it crashes. I have automated backups setup as well in case I should need it.
- Main EC2 server with Python scripts is set up with AWS Cloudwatch alarms and will reboot if it crashes.

---

## Conceptual Solution

| Subject | Description | Solutions |
| :-- | :-- | :-- |
| **Process control** | Ensures everything is running even if system has crashed | [supervisord](http://supervisord.org/), [deamontools](http://cr.yp.to/daemontools.html) [crontab](https://www.geeksforgeeks.org/crontab-in-linux-with-examples/)|
| **Message/job Queue** | Ensures tasks are distributed and the main python process freed | [rabbitmq](https://www.rabbitmq.com/), [redis](https://redis.io/) |
| **Scheduling** | Ensures tasks are executed at appropriate times and intervals | [celery](http://www.celeryproject.org/), [sched](https://docs.python.org/3.4/library/sched.html), [schedule](https://schedule.readthedocs.io/en/stable/) |
| **Concurrency** | Ensures tasks are executed in parallel. | [asyncio](https://docs.python.org/3/library/asyncio.html), [threading](https://docs.python.org/3/library/threading.html), [concurrency](https://docs.python.org/3/library/concurrent.futures.html)|
| **Tasks** | The work to be scheduled | Python script(s)

---

### Short term
#### Assumptions
-  Currently I am trading only one pair, BTCUSD, on one exchange, Bitmex, on one timeframe, 1d. I prefer a simple initial setup to get the candle retrieval going.

#### Solution
The right solution right now is simple cronjob that [runs a main script on reboot](https://stackoverflow.com/questions/24518522/run-python-script-at-startup-in-ubuntu) and a python script with two arguments at specific times.

```
@reboot python /bin/main.py &

* * * * *  python3 schedule.py 1 1
5 * * * *  python3 schedule.py 1 2
0 1 * * *  python3 schedule.py 1 4
0 0 0 0 1  python3 schedule.py 1 6
```
The first argument is my market_id (1: btcusd on bitmex) and the second argument is my timeframe_id (1: 1m, 2: 5m, 4: 1h and 6: 1d).

- **Pro**: Simple
- **Con**: Does not scale well with more pairs, timeframes and exchanges

The max resolution from crontab is one minute, but this can be addressed in the Python script itself, which can do for example five checks ten seconds apart.

This will do for now. It works well enough for a one-man-army, but probably less well in a collaborative setting.

---

### Long term

#### Assumptions
- I will be adding trading pairs, exchanges and timeframes to my strategies going forward. I prefer a distributed queue/message based system in the long run.
- Future timeframes are 1m, 5m, 15m, 1h, 4h, 1d, 7d, 30d.
- Future exchanges are Bitmex, Bitfinex and Binance and more - focus on exchanges that enable shorting.
- Future trading pairs will be many and with several quote assets.

#### Requirements:
- Acquire candle data for each pair, timeframe and each exchange, concurrently and on time.
- Execute trades generated by the trading strategies concurrently and on time.

#### Optional
- Processes are monitored and managed centrally
- Dispatch jobs to a job queue that is then
- Scheduler picks up jobs from the queue and executes them
- Single multithreaded python3 script or several processes on the server as long as the data is acquired and orders executed concurrently in parallel at the appropriate time.

#### Solution
| Subject | Description |
| :-- | :-- |
| **Process control** | [Supervisord](http://supervisord.org/)|
| **Work queue** | [redis](https://redis.io/)|
| **Scheduling** | [Celery](http://www.celeryproject.org/) |
| **Concurrency** | [Asyncio](https://docs.python.org/3/library/asyncio.html) |


---

# Links

## Python modules

### asyncio
- [python.org](https://docs.python.org/3/library/asyncio.html)
- [youtube](https://www.youtube.com/watch?v=xWt5lpn8fN8)
- [tutorialedge](https://tutorialedge.net/python/concurrency/asyncio-event-loops-tutorial/)

### sched
- [python.org](https://docs.python.org/3.4/library/sched.html)

### threading
- [python.org](https://docs.python.org/3/library/threading.html)

### Misc
- [Asynchronous Tasks in Python - Getting Started With Celery](https://www.youtube.com/watch?v=fg-JfZBetpM)
- [Django + Celery + Supervisord + Redis error when setting](https://stackoverflow.com/questions/45904309/django-celery-supervisord-redis-error-when-setting)
- [Multiprocessing vs multithreading vs asyncio in Python 3.4](https://stackoverflow.com/questions/27435284/multiprocessing-vs-multithreading-vs-asyncio-in-python-3-4)
- [Asynchronous-programming](https://luminousmen.com/post/asynchronous-programming-blocking-and-non-blocking)
- [Real Python: Parallel Processing](https://www.youtube.com/watch?v=0NNV8FDuck8&list=PLP8GkvaIxJP1z5bu4NX_bFrEInBkAgTMr&index=6)
- [Async Python: The Different Forms of Concurrency](http://masnun.rocks/2016/10/06/async-python-the-different-forms-of-concurrency/)