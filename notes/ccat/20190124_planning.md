*Coding Journal*
Rasmus Groth
*20190124, Utterslev, Copenhagen, Denmark*

Minion: Ok, so I am done with the order module
Master: Great. Thank you very much!

Minion: What should I do next?
Master: What would we need to do to run the system locally?

Mi: As a minimum something that

---

**?**: How much of our capital do we allow the strategy to trade?
**!**: We start it off with a fixed amount - for example $100. Whatever it makes is added to that balance. Whatever it loses is subtracted.

We will need to build a module that keeps a balance for each strategy and a trader that listens for orders and balances in the database.

### Scripts

##### trader.py (controller)
Listens to the order log and asks the balance.py module how much it should trade and triggers the order module with the amount whenever a trade is queued in the order table

##### balance.py (model)
For each trade, log the base and the quota amounts and tally them up in a current balance for the strategy

### Tables
##### strategy
Keeps a balance, profits, losses and for each strategy by tallying up all the orders. If I want to add or subtract manually from the balance, I do so by issuing a deposit or withdrawal order manually..

?: Hmm - that sounds a bit weird. How would we avoid messing up the profitability tracking?
!: Good point. I'll think about that some more and see if I come up with something.
!: Ok, I figured it out. It is a non-issue. The strategy has nothing to do with the total balance and is not aware of it. It only knows it's own allowance and performance.

I guess the allowance and performance methods should be created as well

##### order
A list of orders, and their status. type(market, limit, deposit, withdrawal), side(buy/sell), trigger, limit

##### (account)
Pulls in balances from all the connected exchanges and adds them up.

**ACTION: Create an `order` table in the database - with a `strategy_id` referring to the `strategy` table primary key**

**ACTION: Modify the `strategy script `to log an order in the `order` table**

**ACTION: Create a `trader.py` script that polls the `order` table for queued orders and triggers the `order.py` script**

**ACTION: Create a `strategy` table that logs `balance`, `profit`, `fees`, `allowance`, `allowance_unit` (usd, btc, %)...**

**ACTION: Create **

**ACTION: Create an `account` table that pulls in balances on all the exchanges**

**ACTION: Create a `holding` view that sums up holdings for each asset**

**ACTION: Create a balance.py script **

---

**?**: How do we allow several strategies to trade at the same time?
**!**: The approach above takes care of that

**?**: What do we need to do to run all of this on a server?
**!**: That is a really good question

**?**: How do we ensure that we can update the candle data table with several different pairs, timeframes and exchanges?
**!**: With some sort of queue system. We could use something like Celery and RabbitMQ - or maybe just the database? We could log updates in a table and just listen for that with schedulling done in Python? I will only be listening to the update table with one worker, so should be ok and.

Wait - there is the bucket_update job-submission. That can be done via a queue table, sure, but could also just be done in code!

**?**: The other issue is concurrent writing to the database as it grows. How do we solve that?
**!**: If we use a multicolumn index with market_id, timeframe_id and time_close to avoid getting duplicates, we will will avoid duplicates.
**?**: Sure, but we still have the issue with the temp table being dropped while another process is trying to use it. How do we address that?
**!**: One way is to run the requests consecutively instead of concurrently. That could be done using a queue in a table, but has the downside of not being concurrent which will be a big problem when we add more markets and timeframes.
**?**: Great - se we need to get rid of the temp table and write directly to the bucket table and ensure that we are using the concurrency capabilities of Postgres.
**!**: That is a good approach.

**ACTION: Remove `bucket_temp` table and write directly to `bucket` while ensuring concurrent r/w access**

**ACTION: Replace SERIAL primary key with a UUID primary key in the bucket table**

**ACTION: Create a PYTHON script that runs tasks concurrently using threading and schedule**

**ACTION: Create a CRON script that triggers the python scheduling script if the server crashes**

## Scripts that need to be triggered by the scheduler
- bucket
- conversion or asset
- account.py
- transfer.py
- trader.py


**?**: Whatevs - this is a huge project. I want to get to trading live asap. What do we need to do to do that?
**!**: Well, since we are only trading one pair on one timeframe on one exchange for now, we could have one schedulling script that:

- Runs the strategy every minute - the strategy triggers an order directly with a fixed amount if there is a signal
- Runs the update script every minute

**ACTION: Modify `momentum.py` to give a single long/short signal**

**ACTION: Modify `momentum.py` to trigger order.py directly with a fixed amount/percentage if there is a signal**

**ACTION: Modify cronjob that runs `momentum.py` every day at 00:00:00 UTC and update.py every hour**

That will work for now. It will not be scalable, but it will be deployed.

I also think we should do these two:

**ACTION: Remove `bucket_temp` table and write directly to `bucket` while ensuring concurrent r/w access**

**ACTION: Replace SERIAL primary key with a UUID primary key in the bucket table**

**?**: Ok - that's better. Please make the plan for the different phases.






testing the strategy, building the support and resistance strategy and actually trading live
